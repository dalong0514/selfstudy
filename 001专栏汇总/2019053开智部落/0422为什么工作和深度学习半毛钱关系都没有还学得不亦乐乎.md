# 0422为什么工作和深度学习半毛钱关系都没有，还学得不亦乐乎
为什么说即使不当程序员，你也需要了解一点深度学习
img

-- New170621001 --
编者按：与其担心未来，不如创造未来。开智部落聚集起一群有创造者气质的小伙伴，他们偏爱输出胜于输入，偏爱知识源头胜于鸡汤碎片，偏爱动手创造胜于一旁观望。同样好奇、担忧或是困惑与人工智能是什么，部落的周瑞珍不止步于好奇观望，直接上手学习。上周，她在开智部落分享，闯入深度学习世界，她学到了什么。。


人类对于人工智能一直抱有无限遐想。
古希腊神话中，火神赫菲斯托斯用金子制造机器人女工，她们不仅可以帮他干活，还可以同他交流。玛丽雪莱笔下的科学怪人，和普通人一样拥有好奇心，追求美好情感。除了出于提高劳动效率，改善生活等考虑，人类痴迷于人工智能，还因为人类也渴望成为造物者，像女娲那样，看着泥土在自己手中幻化成有智慧的生命。
也许这一天还很遥远，人类的探索从未停止。过去几年，人工智能快速增长，前所未有的浪潮汹涌而来。深度学习作为人工智能的一个子领域，在解决复杂学习问题领域的成功已经有目共睹。亚马逊语言助理 Alexa、人工智能围棋程序 AlphaGo、Google 自动翻译，这些技术背后都离不开深度学习。
我也十分好奇，计算机是如何具备学习能力的，于是我参加了开智学堂第一期深度学习课程。作为一个小白，在深度学习摸索的过程中，我发现深度学习是一种新的思维框架。也就是说这个机器学习和他里面很多的理论、世界观，你可以无缝地将它用到生活中、决策中，这也是我在看相关科普文章、八卦新闻、媒体报道，所不能获得的。
学习如织网
新生儿大脑中约有 860 亿个神经元。对大脑的运行而言，神经元数目只是一方面，神经元之间的连接才是决定性的。怎样建立神经元之间的连接呢？通过学习。
神经可塑性（Neuro-plasticity）是指的由于经验原因引起的大脑的结构改变。神经可塑性是近期的发现，过去往往认为在婴儿关键期后，大脑结构往往不发生变化。大脑有神经元细胞和神经胶质细胞构成，这些细胞互相连接，通过加强或削弱这些连接，大脑的结构可以发生改变。
大家都有这样的体会，第一次读到一段文字，往往不会有深刻印象。后来，在某个触动你的故事中再次看到这段文字，或某个具体场景令你联想到它，才在脑海中留下鲜活印象。
中学时很喜欢读诗词，大部分都是过目即忘。某天放学路上，我望着天边的落日，一句话从脑海里涌出：浮云游子意，落日故人情。完全记不起这是谁写的，什么时候读过，甚至有种错觉，似乎是自己想出来的。查书才知道来自李白的《送友人》，这时我才是真正的「记住」了这首诗。
生物学家埃里克·坎德尔（Eric R. Kandel）研究原始动物海兔的神经细胞，发现记忆就发生在神经元的突触上。短期记忆形成时，突触连接的强度增加，长期记忆形成时，不仅是突触强度增加，神经回路中的突触数目也发生了变化。
因此，坎德尔写道：「对需要长期保持的记忆而言，输入的信息必须经过彻底而深入的处理。要完成这样的处理过程，就得留意这些信息，并把这些信息跟记忆中已有的知识有意义地、系统化地联系起来。」
古人云，学而时习之。学习是一个反复印证，互为佐证的过程，也是在不断地增强大脑中神经元之间的连接。深度学习的计算部分，通过线性代数中的矩阵来实现。每列代表一个神经元，也就是它所拥有的权重。一个公式简洁的表达了前面所说的一系列运算步骤。
此处输入图片的描述 此处输入图片的描述

这是我和线性代数的第三次相遇。
读大学时它是令我头疼的一门课，各种矩阵变换令人晕头转向，完全不明白为什么要定义这些奇怪的规则。考研时弄懂了，后来工作中不常用到，又渐渐遗忘。在深度学习课程中，我才明白，原来矩阵可以用在这里。
我们接受的教育有一个奇怪的特点，把知识灌输到了脑海，却没有与现实生活联系。仿佛有一块孤零零的区域，专门用来考试。学生在考试的指挥棒之下赶路，无法领略其中的奥妙。直到多年以后，为了理解新的知识去重温，才明白，原来它是这样使用的。把过去的记忆提取到大脑中，与新的记忆连接，我们同时在织着两张网，一张是虚拟的知识网络，一张是大脑中神经元的网络。
洞穴外的光
到目前为止，我参加了开智学堂的四门课程，坦白说，开智的课程信息密度都很大，稍不注意就会掉队。每期课程都有一些特别优秀的同学，在我还没看懂算法内容的时候，他已经可以和老师讨论算法的性能了。我的状态就是一直在追赶，从来都追不上，但是这样一次又一次「被虐」，我却乐此不疲。
大家可能听说过柏拉图的洞穴隐喻，设想有一个深邃幽暗的洞穴，人被完全禁锢，只能看到前方墙壁上刻意制造的幻象，他就以为这是真实的世界。当其中一人的枷锁被解除，能够自由行动，看到洞穴里的一切，他会开始思考何者为真何者为幻，产生困惑与痛苦。当他走出洞穴，逐步看清事物真相，适应了刺眼的阳光，便不愿意再回到黑暗之中生活。
我们都生活在自我构建的洞穴之中，它可以是你所处的环境，也可以是人生的不同阶段。假如你观察一个孩子，会发现他的喜怒哀乐、行动都是出于本能，是不自知的。随着心智成熟，有一天他会能够意识到自己的情绪，从而调节和控制。这便是一个走出洞穴的过程。留在已知世界中会令我们感觉安全，而探索新知，开拓思维的疆域，则有机会来到更宽广更精彩的世界。对我而言，这就是光。
其实学习的这些课程，在短期内都和我的工作没有多大关联，但是并不意味着它们对我的生活不具备现实意义。在我看来，最好的教育不是仅仅提供知识和答案，而是给你更多疑问，让你对现状产生质疑。
相信很多小伙伴都和我一样，面临这个问题：想做的事情太多，时间不够用，怎么办？在学习认知科学，了解大脑怎样做决策后，开始尝试着简化生活， 把一些不那么重要的事情尽可能地简单化，自动化，减少对认知能量的消耗。在阳志平老师的生活十二问和童牧晨玄老师的分享中都有提及，我就不再赘述。
简化生活，最重要的是处理好与身边人的关系。远方的战争会令我们动容，慨叹过后，生活照旧。但是假如和身边的人，尤其是家人产生矛盾，则会带来一整天的心神不宁。而我们往往更在意自己面对外人时的形象，而忽略了家人的感受。意识到这一点，带来的是行动上的改变。相比两年之前，我能感受到自己能够以一种更平和的心境面对工作和生活。
恐怕终其一生，我都无法成为一名智者，但是这不妨碍我的追寻，以及我的期望：像芒格那样，理性而愉快地度过一生。
-- End --
原文链接： 分享导语：闯入深度学习的世界，我学到了什么？
机器学什么习？
img

-- Note170621001 --
编者按：与其担心未来，不如创造未来。开智部落聚集起一群有创造者气质的小伙伴，他们偏爱输出胜于输入，偏爱知识源头胜于鸡汤碎片，偏爱动手创造胜于一旁观望。同样好奇、担忧或是困惑与人工智能是什么，部落的周瑞珍不止步于好奇观望，直接上手学习。上周，她在开智部落分享，闯入深度学习世界，她学到了什么。。


机器学习，学什么
对于用户来说，可以把计算机当做一个黑盒子，根据输入的数据，处理后反馈结果。可以把处理过程表征为一个模型，或者说一个函数 f()。
对于图像识别程序， 此处输入图片的描述 对于AlphaGo， 此处输入图片的描述 对于语音识别程序， 此处输入图片的描述
这个函数有可能非常复杂，计算机的任务就是把它模拟出来。
假设有这样一组数据，记录了一门课程的结业成绩，a1 是学生的平时分，a2 是期末考试的分数，y 是老师给出的最终得分。这组数据称为样本集，a1，a2 称为特征，y 称为标签。
此处输入图片的描述

我们把数据交给计算机，让它从中学习打分的模型。也就是说，我们期望它能够获得这样一个函数f(a1,a2)，尽可能地满足这一系列等式
f(60,90) =80 …… f(50,65) =75
假如计算机学习到的模型是正确的，或者准确率是可接受的，就可以给这个函数一系列新的输入，让它预测这些学生的分数。
看看如何用深度学习来解决这个问题。深度学习是机器学习的一个分支，基于人工神经网络技术。在理解神经网络之前，要先理解什么是神经元。神经元其实就是一个能够接收输入，对输入进行线性叠加，运算并输出结果的单元。
此处输入图片的描述

为了简化问题，假设神经元直接把线性叠加的结果输出，没有经过其他的运算。 即f(a1,a2)=a1W1+a2W2+b，W1，W2是平时分和期末分数分别所占的权重，但它们是未知的。神经网络的任务就是把这三个未知数W1，W2和b算出来。 此处输入图片的描述
怎么算呢？答案是：猜。当然不是漫无目的的猜，而是按照特定的策略，一边猜一边进行修正。参考下面的流程图。
此处输入图片的描述

先给权重和常数赋一个随机的值，假设是 W1=0，W2=1，b=2。把样本集里的第一行数据交给神经元进行计算。 把计算结果和第一行数据里的真实值进行比较，算出误差。再根据误差修改权重。具体怎样修改权重，有很多种方法，都是基于特定的数学理论，能够保证不断的迭代之后，误差会越来越小。这个基于误差修改权重的过程，就称为学习。学习方法归根结底就是网络连接权重的调整方法。接下来不断地循环以上过程，直到误差变得最小，就获得了最合适的W1，W2和b的组合，也就得到所需的函数。
以上是最简单的，只有一个神经元的网络,它只能表达简单的函数。假如有两个老师给学生打分，他们的意见不一致，各自都有自己的一组权重。那就在网络中增加一个神经元。权重增加为四个。每个老师算出的分数再交给一个神经元进行计算，同样也要添加不同的权重。
此处输入图片的描述 假如输入的特征增加，例如上课次数，平时分，期末得分共同决定总成绩，网络就变为 此处输入图片的描述
当许许多多神经元按一定规则连接起来，构成深度神经网络，就具备了强大的功能。深度学习的「深度」一词指的是层数比较多的神经网络。 此处输入图片的描述
以上就是神经网络的工作原理。具体到特定领域，比如图像识别，也是先人工给大量图片做好标记，这是一只猫，这是一只狗，这是一朵花，再交给计算机进行学习。每一轮学习，它都会根据设定好的方式对权重系数做出修正。当然具体的应用要更复杂，例如 y 值的计算，通常不是简单的线性函数，而是更复杂的运算过程，每一层的计算方法也会不一样。微软在 2015 年 ImageNet 挑战赛中应用的系统具有 152 层神经网络。
人工神经元与大脑神经元
神经元的学习过程令我想起曾经在科学馆里走过的镜子迷宫。当你进入迷宫后，眼前层层叠叠，分不清虚实，前进的方法是用手里的泡沫轴敲一敲，看看是镜子还是路，如果路就往前走，如果是镜子就换一个方向，当走到了死胡同就退回来。
人类大脑做决策也是类似的：不断的接收输入，做出判断，再根据现实与自身判断的差距进行调整。人类的学习是对自我的修正，人工神经元的学习则是对它拥有的一系列权重系数的修正，只是在计算机上精确的量化了这一过程。
1943 年，逻辑学家 Walter Pitts 和神经生理学家 Warren McCulloch 提出神经元模型，其后神经网络研究起起伏伏多年，一度被淡忘，直到 2010 年前后才重新崛起，获得大规模的应用。事实上人工神经网络的发明正是受到中枢神经系统的启发。研究大脑认知机理，再把它运用到计算机上，是实现人工智能的一个重要途径。下图是大脑神经元的构造。
此处输入图片的描述

树突是神经元的输入通道，轴突是神经元的输出通道。一个神经元通常具有多个树突，而轴突只有一条，轴突尾端有许多轴突末梢跟其他神经元的树突产生连接，从而传递信号。这个连接的位置在生物学上叫做「突触」。
1977 年诺贝尔物理学奖得主安德森在论文《多者异也》中指出，物质在不同的尺度会遵从不一样的规律。单个神经元的功能十分简单，当神经元多达数百亿个，心智自然涌现。大脑神经网络之所以具有思维认识等高级功能，正是因为无数神经元之间的联结构成了一个庞大而复杂的系统。
我前面所介绍的内容，都只是简单的，浅层次的理解，可能有些知识也属于「司机知识」。深度学习是一个融合了数学，计算机技术和特定领域知识的多学科交叉领域。在数学理论的指导下，才能保证模型的学习是朝着正确的方向，能够获得最优的结果；在理解了神经网络的原理之后，必须通过编程技术才能真正实现；如何用来解决现实中的问题，计算机怎样理解图像，我们使用的语言文字要怎样转换成计算机可以处理的数字，这些都是需要沉下心来，投入时间才能够掌握的。下一阶段的计划是深度学习「深度学习」。
-- End --