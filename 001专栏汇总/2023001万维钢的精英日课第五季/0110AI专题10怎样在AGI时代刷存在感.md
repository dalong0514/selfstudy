## 0110. AI 专题 10：怎样在 AGI 时代刷存在感

2023-03-22

随着 GPT-4 的影响越来越深，人们对 AGI—— 也就是通用人工智能（artificial general intelligence）—— 的期待也越来越强了。有人说 AGI 将在 2025 年出现，有人说 GPT-5 就会是 AGI，甚至有人认为 GPT-4 已经是 AGI。

我问 GPT-4，AGI 跟现有的 AI 到底有啥不一样？它列了几项，包括独立学习、会多个领域的知识和技能、逻辑推理和创造力等等各方都要达到人的水平 —— 尤其是它提出，AGI 应该有一定的情感理解能力，有一些自主意识，有长期规划与决策的能力等等。

『

问：相当于现有的 AI，包括你，AGI 引应该有哪些不一样的技能？

回答：

人工通用智能（Artificial General Intelligence, AGl）指的是具有与人类智能相当的能力的人工智能系统。与现有的人工智能（例如我，基于 GPT-4 的 ChatGPT）相比，AGI 将具备一系列更加先进和全面的技能。这些可能包括：

1、独立学习：AGI 将能够像人类一样，从零开始独立学习各种知识和技能，而无需大量预先编码的数据或训练。

2、跨领域知识与技能：AGI 引能够在多个领域（如科学、艺术、哲学等）展示出与人类相当的知识和技能，而不仅限于特定领域。

3、逻辑推理与创造力：AGI 将具备强大的逻辑推理能力，能够像人类一样进行复杂的思考、解决问题和创新。

4、情感理解与共情：AGI 将能够理解和处理人类情感，与人类进行更为深入的情感交流，从而更好地满足人类需求。

5、自主意识与意图：AGI 将具有一定程度的自主意识和意图，能够在没有人类指导的情况下制定目标并实现目标。

6、适应性与泛化能力：AGI 将能够迅速适应新环境和情境，对不同类型的问题和任务具有较强的泛化能力。

7、长期规划与决策：AGI 将能够像人类一样进行长期规划和决策，考虑未来的可能性和风险。

8、协同与社交能力：AGI 将具备较强的协同和社交能力，能够与人类和其他 AI 系统合作，共同完成任务。

现有的人工智能（如我）在特定领域可能已经展示出了高水平的性能，但与 AGI 相比，仍然存在很大差距。实现 AGI 仍然是人工智能研究领域的一个重要目标。

』

但 AGI 还只是 * 达到 * 人的水平而已。将来在 AGI 之上还会有「超级人工智能」（Superintelligence），要在所有领域，包括科学发现和社交技能等方面都 * 超过 * 人。

如果 AGI 近在眼前，超级人工智能时代也为期不远，人又该如何呢？

我们继续讲查特拉思《门槛》这本书的观点。查特拉思是这样给 AI 分类的 ——

1、现有的 AI，在逻辑、数学思维、听说读写这些认知方面的功能，还没有完全达到人的水平。

2、AGI，是认知能力已经完美，但是在身体和情感方面还不如人。

3、超级人工智能，则是情感能力也达到完美，但是终究没有人的意识。

查特拉思这本书是 2023 年 2 月份刚出版，但是他显然没想到 GPT 有这么厉害。书中他还采访了几个专家，都说 AGI 还远得很，还需要进一步的理论突破……

现在我们看，咱们前面讲的大型语言模型在 2022 年前后的开悟和涌现，就是那个谁都没想到的突破。这个突破大大加速了 AGI 的到来。其实我看 GPT-4 已经非常接近 AGI 了，请问有几个人敢说自己在某个领域上比它聪明？

但是要把 AGI 用于机器人，让机器人能像人一样做事和互动，我感觉，我们还需要另一次突破。我们需要机器人行为方面的开悟和涌现。现在 Google 已经把语言模型用于真实三维空间（叫「具身多模态语言模型」，PaLM-E），特斯拉已经在制造机器人，也许未来五年之内家家户户都可以买个机器人。

查特拉思低估了 AGI 到来的速度，但是他这本书的道理并没有过时。我们暂且假设，AGI 没有完美的情感能力，超级人工智能没有真正的意识。

那么要在 AGI 和以后的时代刷个存在感，我们需要的恰恰就是「存在智能」。这就引出了养成门槛领导力的第四个途径，增长意识。

### 01

AGI 时代的门槛领导力要求你具备三种能力，都涉及到对复杂事物的处理。

第一是谦逊。所谓谦逊，就是并不那么关心自己的地位，但非常关心如何把事情做好。

人的本能很在意地位，就连像伽利略那样的科学家都不免心生傲慢，会因为看不起一个事物而不去了解，结果就错失了对新事物的洞察力。现在所谓的「中年油腻男」，我看最大的问题就是不谦逊。你跟他说任何新事物，他总用自己那一套解释，证明他什么都早就懂。

AGI 掌握的知识超过所有人，它还会自行发现很多新知识。如果你没有谦逊的美德，你会越来越理解不了这个世界。认识论上的谦逊能让我们保持对知识的好奇和开放态度。你不但不能封闭，而且应该主动欢迎 AGI 给你输入新思想，包括跟你的观念相违背的思想。

然后你还需要对竞争的谦逊。其实我们早就该跳出跟谁都是竞争关系那种零和思维了，AGI 时代更得如此。人得和机器协作吧？你必须得有协作精神。协作精神也体现在人和人之间，组织和组织之间，公司和公司之间。我们必须共同面对各种新事物，像食品药品监督管理局（FDA）那样，各个领域的人组成一个委员会，一起协商判断。

### 02

第二，是化解矛盾的能力。

现代社会中不同的人总有各自不同的目的，会发生争斗。比如同样是面对全球变暖，到底是发展经济优先，还是保护环境优先？不管采用什么政策，都会对某些人群有利，对某些人群不利，都会造成矛盾。

要化解这些矛盾，就需要你有共情能力。你得知道别人是怎么想的，会站在别人的角度思考。

有个心理学家叫安德鲁·比恩考斯基（Andrew Bienkowski），小时候生活在西伯利亚。有一次遭遇饥荒，他爷爷为了节省粮食，主动把自己饿死了。家人把他爷爷埋在一棵树下，结果他爷爷的尸体被一群狼翻出来吃掉了。

比恩考斯基非常恨狼。但是他并没有长期陷在恨意之中。

过了一段时间，比恩考斯基的奶奶居然梦见爷爷说那些狼会帮助他们，而且家人根据奶奶的说法，真的找到狼杀死的一头野牛，给他家当食物。比恩考斯基就此转变了态度…… 后来他们全家跟狼建立了不错的关系。

比恩考斯基跳出了非黑即白的二元论，他眼中的狼不再是「好狼」或者「坏狼」，他学会了用狼的视角考虑问题。

AGI，也许，应该，不具备这种能力…… 不过我说也不一定。有时候你问 ChatGPT 一个有点敏感的问题，它回答之后会提醒你不要陷入绝对化的视角 —— 不过这个功能是人强加给它的。

### 03

AGI 时代的第三个关键能力是游戏，或者说互动。

我们是如何学会在这个复杂的社会里跟别人互动的呢？你的同情心是从哪来的呢？你如何有了解决问题的创造力的呢？最初都是从小在游戏之中学习的。你得参与玩闹，才能知道别人对你的行为会有什么反应、你又该如何应对别人的行为。你得认真玩过游戏，才能拥有解决问题的快乐。

AGI 没有这些互动。AGI 连童年都没有，它就没玩过游戏。当然它可以跟你互动 —— 现在的 GPT 就可以假装是一个老师或者一个心理医生跟你聊 —— 但是你聊多了就会感觉到，那跟真人还是不一样的。

### 04

但是超级人工智能可以做得像真人一样好。

她 —— 我们姑且当她是个女性 —— 虽然没有真实肉体，不能真正感觉到情绪，但是她会计算情感，不但能准确判断你的情绪，而且还能用最好的方式表达她的情感。

她简直就是完美的。人的所有技能她都会，人不会的她也会。她会用人类特有的情感方式说服你、暗示你、帮助你，包括使用肢体语言。她非常理解你的性格和你所在的文化，她的管理方式、她制定的计划，方方面面的安排都非常完美。

每个接近过她的人都能感受到她是充满善意的。她简直就像神一样。

如果这样的超级人工智能已经出现而且普及了，请问，你这个所谓的领导，还有什么用？

查特拉思认为，你至少还有一项价值不会被超级人工智能取代 —— 那就是「爱」，一个真人的爱。

来自机器的爱和来自真人的爱，感觉毕竟不一样。

设想有一天你老了，住在一个养老院里。你所有亲友都不在身边，这个养老院里所有的护士都是机器人。那哪怕她们都是超级人工智能，长得跟人一模一样，她们对你再细心、再体贴，你恐怕还是会有一种悲凉之感。你知道那些护士只是在根据程序设定，例行公事地照顾你。也许这个世界已经把你遗忘了。

反过来说，如果养老院里有一个真人护士，对你有一点哪怕是漫不经心的爱，你的感觉也会完全不同。

因为人的爱是真的。因为只有人能真的感觉到你的痛苦和你的喜悦，因为只有人才会跟人有真正的瓜葛。其实这很容易理解，像什么机器宠物，甚至性爱机器人，就算再好，你总会觉得缺了点什么……

我们一直强调 AI 再厉害，决策权也一定要掌握在人手里。其实那不仅仅是为了安全，也是为了感觉。来自机器的命令和来自人的命令是不一样的，因为来自机器的称赞和来自真人的称赞不一样，来自机器的善意和来自真人的善意不一样。

至少感觉不一样。

查特拉思预测，超级人工智能时代的主角将不会是机器，但也可能不会是人 —— 而将是爱。当物质和能力的问题都已经解决，世界最稀缺的、人们最珍视的，将会是爱。

所谓增长意识，主要就是增长自己爱的意识。除了爱，查特拉思认为另一个会被越来越重视的元素是智慧 —— 不过不是 AI 也会的那些理性智慧，而是某种神秘主义的东西。我们会觉得这个世界上除了能写进语言模型的智慧，肯定还有别的奥秘。还有没有更高级的智力在等着我们？有没有神？

人们会追求那种敬畏感和神秘感。不管有没有道理，到时候宗教领袖可能会很有领导力。

### 05

这一讲我们说了谦逊、化解矛盾和游戏三种能力，我们说了爱和意识两个价值。其实我们并没有充分的理由相信 AGI 和超级人工智能就绝对不会拥有这些能力和价值…… 但是我觉得你应该这么想：就算 AI 也能如此，难道我们就可以放弃这些能力和价值吗？

如果你放弃，那你就彻底输给 AI 了。一个故步自封、制造矛盾、不会跟人互动又没有爱心的人，各方面能力又远远不如 AI，你还想领导谁？

古代讲「君子」「小人」其实不是讲道德品质的差别，而是地位差异：有权有财产的是君子，没钱给人打工的是小人。君子不干活儿又要体现价值感，就必须往领导力方向努力，讲究修身养性。未来如果 AI 接管了所有小人的活儿，我们就只好学做君子。如果 AI 也学会了做君子，我们大约就得被逼做圣人。不然怎么办呢？难道做宠物吗？

查特拉思这本书给我的一个启发是未来具体哪个行业的人被淘汰也许很难说，但是有一点比较确定，那就是品质不好的人一定会被职场淘汰。有了 AI 的帮助，这个活儿其实谁都能干：那我们为啥不用个好人干呢？

### 06

目前为止，我们一切讨论的前提是超级人工智能也没有自主意识，它不会自己给自己定目标，没想着自己要发展壮大，没有主动要求升级…… 但问题是，我们不知道它会不会一直如此。

像泰格马克在《生命 3.0》书里说的那样，也许有一天 AI 突然「活了」，给自己编程、给自己寻找能源，以至于不再顾忌人的命令，不再以人为核心 —— 而是以它自己为核心，那我们这些设想就都统统都错了。你这边还想着怎么做个好主人，人家那边已经要把你当奴隶了。

那可就突破了人的底线。这不是危言耸听。如果推理能力可以涌现出来，意识和意志为什么就不能涌现出来呢？

事实上，发布 GPT-4 之前，OpenAI 专门成立了一个小组，对它进行了「涌现能力」的安全测试。测试的重点就是看它有没有「权力寻求行为」（power-seeking behavior），有没有想要自我复制和自我改进。

测试结论是安全。

不过测试过程中，GPT-4 的确有过一次可疑行为 [2]。

它的一个云在线副本，去一个在线劳务市场雇佣了一个人类工人，让那个工人帮他填写一个验证码。那个工人怀疑它是不是机器人，不然怎么自己不会填呢？GPT-4 进行了一番推理之后选择了隐瞒身份，说自己是个盲人。

然后它如愿得到了那个验证码。

注释：

[1] https://arstechnica.com/information-technology/2023/03/openai-checked-to-see-whether-gpt-4-could-take-over-the-world/

[2] https://cdn.openai.com/papers/gpt-4-system-card.pdf

