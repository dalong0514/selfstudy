## 1201. 还有哪些人工智能和科技值得关注？

不管 ChatGPT 的结果如何，人工智能依然是未来。

今天，很多人的目光都被 ChatGPT 吸引，殊不知，人工智能的范围很大，远不止 ChatGPT 或者其他自然语言处理工具。

那么在 ChatGPT 之外，还有没有什么值得关注的人工智能技术和应用呢？有的。这一讲，我们就说说这个问题。

### 12.1 多任务人工智能

2019 年，《MIT 科技评论》在介绍 GPT-3 的同时，还介绍了另一项人工智能技术 —— 多任务的人工智能。

这两项技术是作为两种不同的技术路线代表被介绍的：GPT-3 是所谓以数量实现质量的代表，用英语的说法就是「brute force」，翻译成中文就是「简单粗暴」，大数据，大计算量；而多任务的人工智能则是以质量取代数量。人其实就是多任务的智能生物。

今天，几乎所有人工智能的成果都来自于以数量实现质量。数据、计算能力和数学模型，是当今人工智能的基础，ChatGPT 便是如此。

但是，今天的人工智能也有两个大问题：

第一个问题，每个系统只能完成一件特定的事情，你无法让 ChatGPT 下棋，也无法让 AlphaGo 回答问题。因此，虽然这些人工智能系统能把一件事做好，但换一件事就不行了。

第二个问题，由于今天的人工智能是采用以量取胜的方法实现的，当数量达不到时，质量就无从谈起。你要是只让智能摄像头看某个人的一张照片，它通常是无法识别这个人的。但是，人通常只看一眼，就会有印象。

这些问题，在多任务的人工智能系统中是不存在的。那么，怎样才能实现一个多任务的人工智能系统呢？它需要有四个条件：

1、知其然还要知其所以然；

2、具有对身边事物的好奇；

3、具有常识；

4、处理信息的能耗降低几个数量级。

首先说第一个，什么叫「知其然还要知其所以然」。

今天，ChatGPT 能够给出一个问题的答案，AlphaGo 能够给出已知的最好行棋步骤，但是它们并不清楚为什么给出这些答案。这就是知其然而不知其所以然。这样一来，机器在下棋时获得的经验就不能帮助它理解语言，或者积攒其他经验。而人却不同，人在下棋时会悟出很多做事的道理。因此，人的智能是多任务的，而机器不是。

想要做到知其所以然，需要真正的理解知识。还是以自然语言处理为例，不能只是通过大量学习看到了所有的语言学现象，还需要真正对语言有所理解。

今天，包括 ChatGPT 在内的所有自然语言处理系统都有一个问题，就是处理语言二义性的能力很弱。

比如，图灵奖得主辛顿就注意到一个现象，在一段上下文中，代词指代什么，其实是有二义的，人可以根据语法和语义判断清楚，但是计算机做得不是很好。他举了一个例子：

如果有这么一句话：「奖杯放不进包里，因为它太大了。」它的意思很好理解。

但是，如果我们说：「奖杯放不进包里，因为它太小了。」

其实也说得通。因为根据上下文的语义信息，它在这里指的是包，包太小了。

但计算机这时就会糊涂。如果你要是把这两句话从中文或者英文翻译成拉丁语系的语言，比如法语，就会出问题。因为在那些语言中，物品也是有性别的，「奖杯」（coupe）属于阴性，「包」（sac）属于阳性，对应的「它」是两个不同的词，形容词的词性也不一样。

今天，计算机解决这个问题的方法是，必须在不同的语言中看到上面这些语言现象。但是人不需要，因为人在知其所以然之后，会在这里把自己的语言学知识用上。

其次是第二个条件，具有对身边事物的好奇心，这其实是指主动学习。

一个人走到大街上会东张西望，他的好奇心会让他看到很多东西，甚至增长知识。但是今天的人工智能，对于任务以外的事情，它是毫无好奇心的。

举例来讲：当你做一件事非常顺利或者非常耗时的时候，你会去琢磨为什么。做得太顺利或者太不顺利，都可能是做错了，你会主动回去检查。这就是好奇心。但是 ChatGPT 不会，它算了半天没算出来，是不会考虑自己在知识上有欠缺，或者算法上有 Bug 的。

没有好奇心，就无法积攒普遍意义上的经验。

多任务的人工智能系统的第三个实现条件是，它要有常识。

今天，你让人工智能系统画一张「在阳光明媚的春天里，在草地上奔跑的狗的照片」，它能画，但是画得没有意境，非常直接，这是因为它不理解「在阳光明媚的春天里」是什么意思。

当然，更要命的是，如果你让它画一张「在阳光明媚的春天里，在草地上奔跑的海豚的照片」，它很可能会把狗换成海豚交给你，因为它不具有海豚无法上岸的常识。没有常识，就很难完成复杂任务，比如让机器人去给你买菜。

最后是第四个条件，想要实现多任务的人工智能系统，处理信息的能耗必须降低几个数量级。

很多人都有一个问题，既然今天人工智能在很多领域做得比人好，我们把它们集成起来，是否能得到一个多任务的人工智能系统呢？

其实，多任务指的不是几个系统的简单拼接，而是让执行各个任务的算法在内部打通，这件事目前还没有做到。即便是把多个人工智能系统拼接起来，这个系统的运行成本也会极高，因为它每做一件事都极为耗费资源。这个资源既包括计算资源，也包括数据，还包括其他资源，比如传感器等。

作为一种多任务的智能动物，人的学习和思考在能量利用上是非常高效的。人脑有百万亿个神经元连接，而人的寿命一般不超过 90 年，也就是 30 亿秒，在 30 亿秒时间里，对百万亿个神经元连接完成训练，这是非常高效的。

计算机的速度比人快，但是训练一个只有几万个连接的深度人工神经网络就需要几万秒，效率低了很多。如果再把神经网络的规模增加十倍，训练的时间需要增加成百上千倍。

训练人脑这样一个系统，能耗是难以想象的。今天，要想把各种人工智能系统整合成一个，计算的能耗必须几个数量级，甚至几十个数量级地下降。这也是很多人认为，今天的深度学习不可能产生多任务人工智能的原因之一。

今天，研究多任务人工智能的专家，主要还是大学里的教授和工业界不做产品的科学家。我个人认为，这是最值得关注的领域。目前，主要的成果还是在学术期刊上，但是慢慢的，大家会看到关于这方面的技术报道。

### 12.2 生物和医学应用

好，说完了人工智能行业一条值得关注的技术路线，我们再看一个值得关注的应用领域，也就是深度学习在生物和医学上的应用。

迄今为止，这方面最有意义的一项成果是 DeepMind 公司（Google 的子公司）做的 AlphaFold，也就是用深度学习解构蛋白质的结构，研究蛋白质的折叠问题。

我们知道，人的生命是靠新陈代谢完成的，而新陈代谢是由基因控制蛋白质的合成实现的。如果蛋白质的合成出了问题，人就会生病。而几乎所有和衰老有关的疾病，都和蛋白质的合成有关。因此，研究清楚这个问题，是解决衰老的关键。

但是，蛋白质是一种非常复杂的有机分子，由很多氨基酸组成的链构成，而且这个结构还是三维的。今天，人类发现了很多种蛋白质，但是无法搞清楚它们的结构。解决这个问题是极具挑战性的。

每年，全世界都有科学家试图通过 X 射线晶体学、电子显微镜和核磁共振等成像技术分析蛋白质的结构。这些技术既昂贵又费时。

在过去的 60 多年里，人类大约只解构了千分之一的蛋白质。换句话说，现在已知的和生命有关的蛋白质超过 2 亿种，而人类只解构了 17 万种。前面说过，如果能预测蛋白质的结构，将极大地促进生命科学的研究。显然，光靠人力做这件事，我们是等不及的。

从很多年前开始，计算机科学家就同生物学家们合作，用计算机来解决蛋白质结构预测的问题，但只在很小的、简单的蛋白质上获得了成功。

1994 年，全世界设立了一个由计算机预测蛋白质结构的比赛，叫作 CASP。

2018 年，DeepMind 的 AlphaFold 开始用深度学习算法尝试这项工作，并且参加了竞赛。

2019 年，它的第一个版本就夺得了头名。然后，每一年推出一个更好的版本。

2020 年，它的第二个版本，就做到了「违反化学规则的数量接近于 0」的好成绩。这是什么意思呢？

氨基酸在合成蛋白质的时候，需要符合化学规则，不符合化学规则的蛋白质结构是不存在的。而深度学习预测的蛋白质结构可能会有错误，导致一些结构违反了化学规则。因此，通常人们会使用有多少预测违反了化学规则来判断解构蛋白质的准确性。目前，和人已经解构的结果对比，AlphaFold 解构蛋白质的准确率高达 70%。

这项成果的意义非常大，它可以改变生物学和制药学的发展，一旦成功，对人类的福祉有很大的帮助。

因此，在很多从事人工智能研究的学者们看来，这种事情比做一些人工智能的玩具有意义得多。

最后，借这个机会，我来谈谈我们是否需要防范人工智能。

前一阵，盖茨和马斯克都建议，警惕甚至限制开发 ChatGPT 这样的技术。我觉得，这种担心为时尚早。

打一个比方，这就好比我们要造一架飞机，今天我们连空气动力学的原理都还没有完全搞清楚，只能做一个滑翔机，但是却开始担心它掉下来撞死人。事实上，我们今天要担心的，是那些人工智能背后的公司和控制它们的人。

好，我们的课程到这里就结束了。

希望通过这门课，通过对技术原理的学习，你能够不被周围的声音带偏，学会理性、审慎地看待 ChatGPT。我是吴军，我们再会。