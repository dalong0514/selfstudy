# 第779期 | 这起医疗事故是谁的错？
> 罗辑思维
2019-08-05

今天咱们聊一个医疗事故，一个发生在美国的，特别离奇的医疗事故。

这件事发生在 2013 年。在美国的加州大学旧金山分校医学中心，一个名叫加西亚的 16 岁男孩去看病，结果医院让他错误地服用了大量的抗生素。这个错有多大的呢？这个孩子只需要吃一粒药，结果医院给他喂进去 38.5 倍的药。

听起来这简直是草菅人命。

那好，原因是什么？是医院医疗水平太差吗？不是。

加州大学旧金山分校的医疗中心，是美国最好的医疗机构之一，综合实力连年进入全美前十。那是医护人员不负责吗？也不是。这家医院的医护人员都是一流的，而且还配备了美国最先进的医疗信息系统。这个系统的责任就是维护安全。甚至药房里取药，都是最先进的机器人，确保精准无误。甚至送到病房的每一粒药，都有自动跟踪系统。即使是一颗药出现在了错误的病房里面，护士都会被准确拦截。

那是系统出故障了？没有。系统没有出任何差错，该有的程序，该出现的警示，全都有，一切正常。那这是怎么回事呢？下面咱们就详细讲讲。

这天，男孩的主治医生需要给他开一种抗生素。

前面说了，这医院的自动化系统特别完善，这医生只要把需要的剂量输入到系统，电脑就能自动计算出这个剂量对应的是多少颗药，又方便又准确。

这个系统有两种输入模式，一种是直接输入这个病人需要多少毫克的药，这种最简单直接。还有一种呢？是要根据病人体重来计算药量，所以医生要输入每公斤体重需要多少毫克，计算机再来根据病人体重来换算。你看，设计得多周到。

但是就在这个选择上，医生犯了一个小错。把 160 毫克的药，输成了每公斤体重 160 毫克。那你算算，这个男孩体重 38.5 公斤，可不就乘了这么多倍吗，变成了 38.5 粒药。

这也没啥事，医生也是人，忙中出错，在所难免。但是没关系啊，有自动化系统，给人纠错。

自动化系统是不会漏掉这个小错误的，电脑上弹出了警报，因为这个药量超过了系统允许范围的上限，它想提醒医生再次确认。但是，医生随手关掉了警报。

哎，问题来了，这医生怎么能直接关掉呢？这不是失职么？

要说失职也可以，但是这个情况很难避免。

为啥？因为这家医院的医生每天都会收到几十次警报，每小时就有好几次啊，只要药量超过正常标准 0.1 毫克就会发警报。其实只要在允许的范围内，药物剂量有细微的误差是没问题的。但是，机器不能容忍任何误差，它也没办法根据实际情况做调整。

事故发生后，有调查人员专门去统计过，在这家医院里，临床医生每个月要面对系统发出的一万七千多次警报。对，你没听错。每个月一万多次。在这个频次下，谁都会把警报当成耳旁风的。

举个我自己的例子。前几年电脑还用优盘的时候，微软系统要求正常的操作流程是每次要先点击弹出优盘，然后再把优盘拔出来。但是我有几次忘了，直接拔了，发现也没啥问题，文件也没有丢失。那就胆大了，每次都直接拔。电脑报警可不就当成耳旁风了吗？每次都喊狼来了，每次狼都没来，这种警报跟没有一样。

回到那家医院。医生觉得，这次警报不过就是他每天都会遇到的、可以忽略的正常提醒而已。本来可以纠正错误的第一个机会，就这样被忽略了。

这个订单发送到药剂师那里。同样，药剂师的系统也弹出了警报，但是药剂师也忽略了。原因和前面一样，药剂师每天会收到的警报比临床医生还要多。而且药剂师觉得，前面医生那都有警报提示了呀，医生肯定核对过了。这样，第二个可以纠正错误的机会，也被忽略了。

下一步，药物订单发到了药房。这个药房里就有我们前面提过的机器人，它是医院三年前花了 700 多万美元引进的，可以依据订单打包好药物，分发到对应病房的架子上等着护士来取。机器人准确、准时，不用休息，不会分心，简直是防止取药出差错最完美的解决方案。

机器人严格按照订单的指令完成了自己的任务，装好了 38.5 粒药，贴好安全条码，没出任何差错。但是，机器人再厉害，也判断不出一个人类病人该吃多少药才合理，它只会按照指令完成自己任务。

在过去的人工取药时代，所有的药拿出药房时，药剂师都会再次检查确认。如果还有这一步，没准儿就不会出现这个失误了。但是，医院花了这么多钱整了个机器人，就是为了解放人力，还能准确无误。于是医院把人工检查这一步取消了。

护士取了药准备分给病人的时候，一看这么多抗生素，觉得不太对劲。她扫描了这袋药上的安全条码，发现病房、病床、病人姓名都没错，这药就是这个病人的，药量和医嘱里写的也完全一致。护士反复核对，她也打消了自己的疑虑。

要知道，过去最容易出现药物管理风险的，就是护士分药这一步。但是这个安全条码完美解决了这个问题。如果扫了一个错误的药，系统会立刻提醒「这个药错了，病人的医嘱里没有这个药」。有了这个系统，安全条码已经纠正了很多错误，护士们对它是百分之百的信任。一个原本用来纠正错误的条码，反倒给一个大错误开了绿灯。最后，这 38.5 片抗生素送到了男孩面前。

这前面一步步没办法了，但是病人自己总能发现不对劲儿吧，一下多出这么多药，他肯定得问医生呀。

要不怎么说这件事离奇呢，因为每一环都太巧合了。这个男孩身体一直不好，从小就是医院的常客，时常要服用各种各样的药丸，突然多出一些药，对他来说根本不是啥稀奇事儿。所以他没多想就直接服用了。结果 6 小时之后，他昏迷了，四肢剧烈抽搐，呼吸停止。

幸运的是发现及时，他被抢救过来了，在重症监护室观察了很多天。但是过量药物带来的副作用会有多大影响，谁也说不好。

好，我们再来复盘一下这个离奇的医疗事故。

我们这一代人有一个根深蒂固的观念，就是人是不可靠的，用机器来约束人，控制人，甚至是主宰人，是建立一个安全系统的可靠办法。

但是，如果真的把安全问题都交给机器来处理，那就至少会发生三件事：

第一，机器太能干了。和人相比，它能处理复杂得多的事务。所以，机器天然就会增加系统的复杂性。比如，一个小诊所，如果没有这个机器，就不会搞出什么开药的两个选项，病人需要多少药，就开多少呗？怎么会搞出根据体重再来计算药量这个新花样呢？系统越复杂，对应用这个系统的人，要求就越高，出错的机会其实越大。

第二，机器太可靠了。因为有了这个系统，人就会被反向驯化，对这个系统深信不疑。原本可以避免的错误，就会因为对系统的盲目信赖而酿成悲剧。刚才我们讲的这个故事里，那个药剂师是这样，那个护士是这样，那个病人小男孩也是这样。

第三，机器太强大了。一个小错误，在这个系统里，进入了一个增强回路，逐级放大，最后形成一个荒谬的结果。

那问题又来了，今天我们谈的是系统安全问题。难道不信任机器，再回头去信任人吗？这个话题，我们明天接着聊。

参考文献：

《数字医疗》，罗伯特·瓦赫特，中国人民大学出版社，2018

