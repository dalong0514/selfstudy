# 0211教是更好地学 | 作家部落
2017-04-30 黄忠 借智而行
img

— Live161117003 —
十三维按：如果你仔细想下，会发现历史的大牛绝少是孤身的世外高人，而大多数都有一个身份：老师。这是因为他们本身牛所以吸引了很多学生吗？答案并没有那么简单，甚至可能恰恰相反。一个「反常识」思想出现，一定需要更多的证据使它信服。在开智作家部落的黄忠同学，为此就进行了深度追问和研读，并且在直播中进行了分享。来看看他是怎么说的。以下全文约 7500 字，阅读时间约 10 分钟。
img

主播介绍
黄忠，IT 潮流追随者和终身学习者，从云计算到大数据，再到人工智能。 今年从北京美团回到深圳京东，本想在新的城市安静读书、写文章， 不曾想被卷入开智黑洞，信息品味突变。
引子
阳志平老师曾提出「学习六思」，第四条是：
输出大于输入：即使在头脑中想象教别人，也能提高学习效率；从学到教，意味着从被动到主动，从依赖到独立。
读罢后，我没有就简单的理解一闪而过，而是产生了一连串的疑问：
输入和输出到底是什么？
在学习过程中有哪些输入和输出？
如何区分输入和输出？
什么是更好的输入和输出？
为什么输出大于输入？
大多数人理解的输出，是所谓的写，输入的过程，就是简简单地阅读，即：「输入＝阅读，输出＝记录」，真是这样吗？ 后来我经过研读和思考才发现这样理解带有偏差，至少是不完整的。今天的主题「教是更好地学」，就是想来和大家一起讨论以上几个问题。
从数据谈起
我现在的工作是解决数据的存储、计算和挖掘等问题。举个例子，开智在双十一特别推荐了一系列好书，估计大家在京东买了不少。那么当用户们每天在京东进行登入、点击、下单、评论等操作，就都会产生相应各种数据，这些数据都会被分门别类地记录，被服务器存储下来。
而针对不同的用户行为数据，不同业务会对这些数据进行不同的计算。比如你这个月在京东花了多少钱，买了哪些商品都是不同的计算。
大家上京东会发现有商品推荐给自己，比如你之前买过化妆品，那么推荐给你的很有可能是另外一些化妆品，这就是「机器学习」的问题，我们先来理解「机器学习」。
「机器学习」专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。它现在甚至可以说是人工智能的核心，广泛应用于人工智能的各个领域，它主要使用归纳、综合而不是演绎的方法，通过算法指导计算机利用已知数据得出适当的模型，并利用此模型对新的情境给出判断。
以上大致就是我的工作内容。
那么上面说了这么多，「机器学习」和我们人类的认知、学习有什么关系呢？
当然有，而且很大，不仅仅是因为它是对人类学习过程的模仿，而且二者都符合信息处理过程的一般抽象。人类的学习机制同样是根据过往的经验，对一类问题形成某种认识或总结出一定的规律，然后利用这些知识来对新的问题下判断的过程。所以我们可以从「机器学习」的原理获得学习的启发。下面就这个问题详细谈下。
「机器学习」的启迪
一般抽象的信息处理过程，可以总结为「输入 - 处理 - 输出」，但对于「机器学习」来说，其中处理有一个核心的概念，叫「模型」，对「机器学习」来说，过程就是「输入 - 模型 - 输出」。
「机器学习」的输入包括数据的输入，「机器学习」的「模型」指的是信息处理的数学模型。把数据输入给机器，在计算机进行「机器学习」完之后，它自己会获得到一些新的信息和知识——这些结构的知识，比如对信息分类，类似于人类的经验，会自己形成一个模型，这就是所谓「无监督学习」。比在双11在购物网站用户发生了一系列的行为，传统数据挖掘是需要事先定义后各种行为关系和分类的，但在「机器学习」中,它可以更加智能化对用户行为数据进行自动分类，从而自己生成一个分类，这就是所谓「聚类」。然后我们就可以拿这个模型去做一些预测。上面就是「机器学习」这一分支的大概过程。
我们的人脑学习的过程也是一样的，也有输入和输出，中间是归纳总结出一个规律的过程。比如我们的视觉和听觉都是我们大脑输入的一部分，当我们接收到这些信息之后，大脑它自己会去做一个深度的思考，或者说做一些知识的连接，通过归纳或者演绎等方法，得到一些规律，然后我们用这个规律来预测指导我们未来的行为或者决策，这就是我们学习的一个过程。下面是一张对比图：
img

对比机器学习和人脑学习，都有输入和输出，中间有一个环节，如果是机器学习则是模型，如果是人脑则是规律，也可以理解为模型，接下来讨论这三部分：
第一部分是输入，「机器学习」过程中数据的真实性、丰富性，以及数据量是对这个模型来讲，都非常依赖于输入，如果输入的数据足够丰富、足够的真实、没有噪音，那么训练出来的模型，误差会比较小；大脑学习同样依赖输入，丰富真实的数据至关重要，这就要给大脑减少垃圾信息和数据的获取，比如大多数网站或者公众号的碎片知识，因为它会对真实的信息产生干扰，这就是为什么需要获取源头知识、多学科知识，基于原始信息学习到的模型价值更高。
第二部分就是模型本身，机器学习应用中，会尝试使用不同的模型来拟合数据，或者做优化，或者创造模型。大脑学习也一样，尝试不同的方法或者借用更好的经验来总结规律，好的规律和模型能解释更多的现象，解决更多的问题，就像阳志平老师经常会提到芒格的薪资核算模型，就是很好的模型。当然，模型本身也需要不断演化。
第三部分模型能不能预测，或者说预测准确度如何，得到模型之后，就要验证模型到底好不；人类学习一样，通过验证和运用知识来检验学习的效果。
上面三点是「机器学习」和人脑「输入 - 模型 - 输出」的对比，也是知识的迁移，算是把机器学习和人脑学习两个知识打通了。
总结如下：

![](https://raw.githubusercontent.com/dalong0514/selfstudy/master/图片链接/碎片图片/2019083.png)



人脑的记忆模型

人脑的「工作记忆」模型。
img

「工作记忆」模型细化之后就是下面这张图：

![](https://raw.githubusercontent.com/dalong0514/selfstudy/master/图片链接/碎片图片/2019084.png)

img

可以看到，人类有三种记忆类型。第一种「感知记忆」，其中的感知器就是我们的眼睛、耳朵、触觉等感官接口，我们从中能获得外界刺激的各种信息。第二种「工作记忆」，大脑基于「感知记忆」，将信息加载到「工作记忆」中来。「工作记忆」和「感知记忆」的时间非常短，而并且容量是极其有限。第三种记忆就是「长期记忆」。所谓长期性就是针对已有知识的记忆，其记忆容量非常非常大的，几乎就是无限的水平，这要看你能挖掘多少了。「长期记忆」根据来源也分两种，一种是来自于无意识接收至「感知记忆」中所获得的「情景记忆」(episodic)，另一部分就是在「工作记忆」加工处理过的「语义记忆」(semantic)，以上就是记忆的三种类型。
「长期记忆」这一部分有两个核心的概念，是加州洛杉矶分校的一对夫妻教授（Robert Bjork和Elizabeth Bjork）提出来的一个记忆模型——即通常心理学所说的「必要难度理论」（Desirable Difficulty)，认为在记忆过程中有两种强度，一种是「存储强度」，一种是「提取强度」。并且二者在记忆过程中具有以下特点：
「存储强度」和记忆的「提取强度」是负相关的，可以理解为输入越快，提取越慢。
「存储强度」是只增不减，如果我们在不同时间、空间反复学习同一个知识，存储强度会得到加强。
我们常常有这样的感觉经验，即虽然我们好像记得了很多东西，但最后还是忘了，这其实就是因为「提取强度」的不够。
那么如何提高「存储强度」和「提取强度」呢？可以尝试阳志平老师之前提出的方法：6个小时以后再记笔记。6个小时后回忆，记住的反而那些比较重要的东西，重新复习这些内容，就相当于做了一次提取的同时，又做了一次存储，因此我们「长期记忆」过程就会大大加强。如果之前没有练习过，刚开始做会比较困难，可能要绞尽脑汁才能想起一点点东西，但慢慢习惯之后就好了。上面介绍的就是「必要难度理论」。
从记忆模型中得到以下两个结论：
第一，学习知识，重点在于「长期记忆」，也就是最终积累了多少知积。从记忆过程和原理来看，我们在输入端应该少花一些时间，在输出端应该是多花一些时间，因为输出的时候我们也是在提取，而提取不仅会增强我们的「提取强度」，也会加强我们的存储强度。我们越是反复提取已有的知识，以后会更容易提取这些知识。
第二，从另外一个角度可以得出，「输出」大于「输入」。在输入端花的时间应少些，在输出端（提取或生成）上花的时间应多些，因为后者包含了有效学习所必需的“必要难度”，这也从时间上得出了输出的时间应该大于输入的时间，所以输出大于输入有多层含义，也包括提取的次数大于输入的次数。
教是更好地学
从前面讲的理论可以看出，教依赖于被教的对象，写作只依赖自己，这就是为什么写是我们最常用的输出方式，但输出的质量依然取决于提取强度，在教的过程中好的问题会加强提取强度。
这样我们最终走向了「教是更好地学」整个结论。现在有没有什么方法上的例证呢？当然有的，比如「费曼技巧」。
费曼技巧第二条：设想一种场景，你正要向别人传授在白纸上写下你对某个概念的解释, 就好像你正在教导一位新接触这个概念的学生一样。当你这样做的时候， 你会更清楚地意识到关于这个概念你理解了多少, 以及是否还存在理解不清的地方。
费曼技巧是假设一种场景模拟自己在对另外一个人讲。但如果我们身边是有真实的人，这样效果将是最好的。因为作为一种真实的场景，不同于我们凭空想象的那个场景，知识在大脑处理的过程也和相信是不一样的，真实场景中会有「感知记忆」中参与进来。但是我们大多数情况下身边都没有另外一个人，那么就假设有另外一个自己，两个人好像在对话一样，通过自己给自己提问的方式做练习。
无论是回忆还是写笔记，变换时空，在不同情景下提取，加强记忆「提取强度」。比如前面提到6小时候后记笔记是时间上的「必要难度」，还可以通过更换地点造成地点上的「必要难度」。
前面原理中我们也看到了，其中不同场景下「感知记忆」感知不同的内容会参与进来，因此记忆的内容会重新编码存储到我们的记忆系统中去。就好比，如果你特别伤心或者特别高兴，在特别情绪化的时候，有一些特定内容是更容易记住的。
比如著名的学习大神 Scott Young ，他提到一个细节，在学习一个东西的时候，能否向一个10岁的小孩，用比喻的方式解释清楚？用比喻的方式其实就是切换了知识所处的背景（环境）。
古罗马著名斯多亚学派哲学家塞内加（Seneca）曾说过：
While we teach, we learn
而中国古话也说「教学相长」，可见古人也是认识到教对于学的重要性。不过我们今天能从「机器学习」、「工作记忆模型」和「必要难度理论」中得出更确切的结论，也显然比古人更进了一步，让我们可以挖掘更多方法和技巧去实践这种学习方法。
就好比，我今天进行直播，给大家讲「教是更好地学」，就是对自己一次极大提高（笑）。
好了，我直播到这里结束了，感谢大家参与！
拓展阅读
《不确定状况下的判断》第32章
《超负荷大脑》第5章
Learning_by_teaching https://en.wikipedia.org/wiki/
Why teaching someone else is the best way to learn http://ideas.time.com/2011/11/30/the-protege-effect/
Learning_by_teaching http://www.developingteachers.com/articles_tchtraining/koblenz1_jody.htm
[1] Marois, R. & Ivanoff, J. (2005). Capacity limits of information processing in the brain. Trends in Cognitive Sciences, 9(6), 296-305.
[2] Baddeley, A. D. (1997). Human Memory: Theory and Practice: Psychology Press.
（整理 编辑：十三维 2016-11-27）
- The End -