# 数据分析这点事：如何看懂数据 用好数据？
> caoz 2013 年 04 月 15 日

先声明一下，按照传统的定义，我还真不是数据分析高手，各种关联算法，只会最简单的一种「话说不少场合还算管用」；各种挖掘技术，基本上一窍不通；各种牛逼的数据分析工具，除了最简单的几个免费统计平台之外，基本上一个都不会用。所以，各种高手高高手请随意 BS，或自行忽略。这里说点高手不说的。

从微博段子说起，微博上关于数据分析有两个段子，我经常当作案例讲：

第一个段子，说某投资商对某企业所属行业有兴趣，要做背景调查，甲是技术流，一周分析各种网上数据，四处寻找行业材料，天天熬夜，终于写出一份报告；乙是人脉流，和对方高管喝了次酒，请对方核心人员吃了顿饭，所有内幕数据全搞定，问谁的方法是对的。

第二个段子，某电商发现竞争对手淘宝店，周收入突然下降了 30%，但是隔周后又自然恢复，中间毫无其他异常现象，于是老板让分析师分析，苦逼的分析师辛苦数日，做各种数学模型，总算找到勉强的理由自圆其说，老板读毕，虽说不能让人信服，却也没有更合理的解释，某日，见对手老板，闲聊此事，“你们某段时间怎么突然收入下降？”“嗨，别提了，丈母娘去世了，回家奔丧，公司放羊了。”老板恍然大悟。

两个段子，第一个段子，微博上一边倒的说，苦逼分析没有人脉有用；第二个段子类似，一边倒的认为，人脉的消息比苦逼分析管用多了。但是我想说的是，这个解读绝对是错的！

先说第一个段子，其实网络不乏这种「人脉达人」，特别是媒体圈，一些所谓的「IT名记」或者「著名评论家、分析师」和各种互联网大佬称兄道弟，天天秘闻不断，但是呢？他们从不研究产品，不分析用户，所以，他们知道了数据，却不懂数据背后是什么，更不知道什么是重要的，什么是次要的，我有时会批评身边这样的朋友，别天天觉得自己知道几个互联网大佬的花边新闻，就当自己是资深业内人士了，正因为掌握这些东西又觉得炫耀，才反而忽视了真正有价值的信息和有价值的数据。这就是为什么混网络媒体的，见过市面的各种达人，在互联网创业浪潮里，几乎没有成功几率的真实原因，自以为人脉广泛，无所不知，其实正因为缺乏最基本的数据背景分析，所以才是看上去什么都懂，细究下其实什么都不懂。请记住一点，除非你是富二代，官二代，衔着金钥匙出生，那不在我的讨论范围里，否则，没有苦逼的经历，就没有牛逼的成就。

我常订阅一些著名分析师的微博，他们透露的数据往往是很有价值的「这是我订阅的原因」，但是他们的解读通常是惨不忍睹的，这就是只看表象的恶果，而且随便翻看一下他们的数据解读，可以说他们的数据感和数据认知贫乏到可笑，甚至缺乏最基本的数据校核和考证的能力，他们拿到了某公司核心数据又怎样？没经历过苦逼的分析，他们其实什么都看不到。

第二个段子同理，如果不是持续有效的数据跟踪，怎么能得出下降 30% 的结论，这一数据结论与人脉得到的消息相互验证，才会得到完整真实的结果，否则仅仅是闲聊，你怎能知道对方企业管理对业绩影响的范畴，苦逼的分析也许一时没有人脉的消息管用，但是你所得到的对数据的认知和积累，是人脉永远不会给你的。

所以，再次强调，基本的数据跟踪和日常的数据感养成，绝不是可以忽略和无视的。人脉情报可以成为数据解读重要的信息来源，但是绝不能喧宾夺主，替代基本的数据分析工作。

下面说一下数据感，什么是数据感？就是别人说一个数据出来，你会琢磨一下这个是否符合常理，与你日常的数据观测经验是否一致，如果不一致，那么可能的理由是哪些？ 比如 12306 号称一天几十亿次点击，如果你有数据感，第一眼就会质疑这个「点击」定义的合理性；比如曾经有人说某国内图片分享网站一天多少亿访问量，第一眼就知道这个「访问量」定义是有歧义的，「事后官方解释是图片加载量，这个和访问量差异几十倍。」数据感需要不断的培养，和基本的逻辑「比如你应该知道中国有多少网民，每天有多少人上网，一个大概什么类型，什么排名的网站会覆盖网民的比例是多少」，以及善于利用各种工具，我以前在巨头公司，得益于公司巨大的数据资源，可以看到很多互联网的核心数据；但是离开后，才发现，其实互联网上公开可获取的数据途径是非常多的，而且善于利用的话非常有效。每天去查询一些感兴趣的数据，经过一段时间积累，想没有数据感都难。

作为公司或团队负责人，怎么培养员工的数据感，我其实也有一个建议，平时可以搞一些小的竞猜，比如团队集体竞猜新产品或产品改版上线后的日活跃用户，或者 pv 数字，或者收入数据，等等；然后看谁的最准，一种是惩罚制，最不准的请最准的喝奶茶，吃冰淇淋；另一种不惩罚，最准的累计积分后公司可以发一些奖品鼓励，这样下去大家的数据感就会在日常培养起来，而且对团队的气氛培养也有帮助。

数据感之后，谈数据分析的方法，我的建议是，不炫技，不苛求技术复杂度，最简单的数据，所包含的信息往往是最有价值的，而很多人恰恰这一步都没做好，就总想着弄一堆挖掘算法；数据的价值在于正确的解读，而不是处理算法的复杂度，切不可喧宾夺主。 大公司的 kpi 制度，往往会产生偏差，比如技术工程师的评定，要讲究「技术复杂度」、「技术领先性」，直接导致简单的事情没人肯做，最基本的工作不认真做！所以往往是大公司的分析工程师，为了评高级工程师，非要简单问题复杂化，四则运算就搞定的事情一定要弄一套诡异的算法，最终非但浪费了资源，消耗了时间，而且往往由于工程师对业务理解的漠视，对应的产品人员又对算法的陌生，导致了严重的理解歧义，从而出现各种误读。

下面说关键，数据解读，正确的数据解读，是所有数据分析工作最关键的一步，这一步错了，前面的所有努力都是白搭，然后，往往很多人简单的以为「数据会说话」，他们认为把数据处理完一摆就 ok 了，所以我看到很多知名分析师拿着正确的数据信口胡诌；而更有甚者，显然是故意的行为，一个非常非常著名的、口碑极佳的跨国企业，曾经就同一份很酷的数据，在不同的场合下，为了市场公关的需求，做出不同的解读；这简直就是道德问题了。

数据解读，不能是为了迎合谁，要遵循数据的本质，要遵循科学的逻辑，要有想象力「配合求证」，可能有时候也需要依赖人脉关系所获得的情报，「这个也有很多典型范例」，这个具体再怎么说可能我也说不清楚，说几个反面例子也许更容易理解。

1、因果关联错误，或忽略关键因素，A 和 B 的数据高度相关，有人就片面认为 A 影响了 B，或者 B 影响了 A；但是，有时候真实原因是 C 同时影响了 A 和 B，有时候 C 被忽略掉了。

2、忽略沉默的大多数，特别是网上投票，调查，极易产生这种偏差，参与者往往有一定的共同诉求，而未参与者往往才是主流用户。

3、数据定义错误，或理解歧义，在技术与市场、产品人员沟通中产生信息歧义，直接导致所处理的数据和所需求的数据有偏差，结果显著不正确。

4、强行匹配；不同公司，不同领域的数据定义可能不一致，在同一个公司内或领域内做对比，往往没有问题，大家对此都很习惯，却有评论家不懂装懂，强行将不同定义的数据放在一起对比做结论，显著失真；海外著名金融机构在分析中国页游和端游市场就连续犯这类错误。

5、忽略前提；有些数据结论是基于某种前提，符合某种特定场景下得出的，但是解读者有意或无意忽略前提，将结论扩大化，显著误读。

6、忽略交互；在商业模式改造和产品改进，往往都会出这类问题，最简单说，你游戏中的道具降价，对收入的影响是增还是减？如果忽略交互，仅仅依赖于数据推算，当然是减，但是实际呢？做运营的都知道。

7、缺乏常识；如果对一些重要的纪念日，节日，或者网购节不了解，那去处理有关数据显然就不知所云了。做行业报告更是如此，很难想像对行业不了解的人能做出怎样的报告。

8、无视样本偏差；我们通常做数据调研，是基于样本数据，而采样过程本身很难做到完全的公平和分散，样本偏差要控制在合理范畴内，即便无法控制，在结论中也需要标注；这才是严谨的数据解读，对样本偏差视而不见，甚至为了某种宣传目的刻意寻找偏差的样本，都不可能做出好的数据结论。

那么， 数据处理也多说一点，虽说是个技术活，但是有些不那么技术的事情，也必须做到位才行；很多时候，我看到一个数据，不符合我的预期，我第一反应，是了解数据来源和处理逻辑，我们通常面对的数据，包括大量的干扰，噪音数据，以及一些识别上容易产生歧义甚至误判的数据，这都是需要处理的，很多时候工程师只关心算法层面、效率层面，不愿意也不关心这些东西，所得出的数据结论失真度就非常高，越是大公司，这种情况越普遍；在我效力的巨头公司时，这样的范例非常多，处理方法其实很简单，多看看源数据，对中间的噪音和干扰数据正确识别标注，对容易误判的数据进行二次判定，全是苦力活，没啥技术含量，但是这是必须的。

最后，很多人想知道我怎么看数据，或者想问我，他们每天看很多数据，不知道怎么去看，我其实有很简单的三板斧，一学就会，一用就灵，对常见的数据场景，可解决绝大部分日常需求。 简单说就是「对比，细分，溯源」六字真言，没了。

对比，数据放在那里，是没意义的，你说你游戏周流失率 80%，啥情况？不知道，你问我我也不知道。对比起来才知道。

一是横比，你拿出 50 款游戏来比，别人平均流失率 90%，你 80%，你游戏还不错勒，别人要平均流失 65%，你 80%，这就有问题了。

二是纵比，和自己时间轴比，你两个月前 1.0 版本流失率 90%，你现在 80%，有进步么，你要是两个月前是 50%，现在 80%，好好反思喽。

所以，我特别强调，在通常企业数据监控，显示一大屏数据的界面上，对比特征要最大体现，比如所有同比下降超过多少比例的一概红色体现，所有上升多少比例的一概绿色体现，公司运营状况一目了然。

细分，数据出现对比异常，你当然想知道原因，那就需要细分了。

细分先分纬度，再分粒度，什么是纬度？你按照时间去分，就是时间纬度，按照地区去分，就是地区纬度，按照来路去分，就是来路纬度，按照受访去分，就是受访纬度；你说今天网站访问量涨了 5%，咋回事不知道，你细分一看，大部分网页都没涨，某个频道某个活动页涨了 300%，这就清楚了，这就是细分最简单的范例，其实很多领域都通用。 粒度是什么，你时间纬度，是按照天，还是按照小时？这就是粒度差异，你来路纬度，是来路的网站，还是来路的 url，这就是粒度的差异；这样可以将对比的差异值逐级锁定，寻找原因。

溯源，有时候我对比，细分锁定到具体纬度，具体粒度了，依然没有结论，怎么办，溯源，依据锁定的这个纬度和粒度作为搜索条件，查询所涉及的源日志，源记录，然后基于此分析和反思用户的行为，往往会有惊人的发现，我们正是基于这一逻辑发现过产品的一些缺陷，而且你不断通过这个方式分析数据，对用户行为的理解也会逐步加深。

其实，这个话题还有很多延伸，比如，如何看一个年轻人有没有数据分析潜质；以及如何培养数据分析和产品分析人才，等等，不过，就这样吧。今天说的不少了，我水平有限，吃饭的就这几招，而且又老又笨，大家都会了我离下岗也不远了，您就凑活看吧。



