## CH0201. 技术准备

[‌⁢‬‍欢迎来到AI阅读新世界 - 飞书云文档](https://anrenmind.feishu.cn/wiki/IbUOw7GMliIWCEkSivVckVx6nOg)

### 音频整理

在这次的「技术准备」讲解中，我会详细阐述在接下来的课程中会反复出现的一些概念。我将按照系统阅读法、文本大法和 GPT 的顺序进行介绍。首先，我们来看一下什么是系统阅读法。在第一讲中，我们对系统阅读法已经做了一个简单的了解。简单来说，系统阅读法包含五种具体的阅读技法，分别是文本细读、抽样阅读、结构阅读、主题阅读和卡片大法。这五种技法的应用，实际上都是基于认知科学原理。

例如，文本细读，就是逐字逐句的阅读，并对其进行反复阅读，我们主要的目的是对话作者，充分利用我们大脑的常识、记忆容错率和情境适应的优势。抽样阅读则是带有假设的阅读，利用我们大脑强大的模式识别能力，通过识别并对比模式来获取知识。

结构阅读的技法是带着框架去读书，通过理解作者的思考方式，形成一个易于记忆的知识架构。主题阅读是围绕同一主题阅读多本书，通过相互参照找到关键知识点，它利用了认知科学的快速命名和模式识别原理。

卡片大法则是通过撰写笔记卡片的方式提取知识。每种阅读技法下，包含了更细颗粒度的阅读技巧，在课程的第二部分，我们也会详细解释如何结合 AI 技术来使用系统阅读法进行读书。另外，系统阅读法也非常适合进行灵活的组合使用。

下面，我们以《聪明的阅读者》这本书为例，具象化理解系统阅读法的应用。首先，当你手里拿到这本书的时候，你首先要做的是确定这本书是一种什么样的书，这是一个什么样的类型的书。明显的，我们可以知道，《聪明的阅读者》是阳志平老师撰写的关于阅读原理的书，这是一本学术专著。然后我们应确定学术专著的阅读顺序，阅读完后我们要将每个环节撰写的卡片整理成书评。

以上我们通过一些信息推断，这是一本学术专著。学术专著的阅读顺序又该如何确定呢？这需要我们对学术专著的特性有深入的了解。虽然学术专著是获取知识的一种重要图书类型，但阅读时我们可能会遇到一定的困难。

当我们阅读学术专著时，往往难以形成对整本书的全面理解，特别是其中充斥着各种专业术语和难懂的概念，这就需要我们掌握一定的学科知识才能理解。因此，我们推荐以下阅读顺序：先进行结构阅读，然后是抽样阅读，接着是文本细读，最后是主题阅读。在此过程中，「卡片大法」可以融入到各个阶段。

首先，我们确定《聪明的阅读者》是一本学术专著。然后，我们采用之前提及的结构阅读、抽样阅读、文本细读的顺序进行阅读。进入第三步，也就是真正开始阅读的阶段，我们对这本书进行了框架性、整体性的结构阅读。

在结构阅读中最重要也最难的部分就是确定作者的认知方式。要进行这样的判断，你需要对主流的认知方式有一定了解，例如，知道什么是思想实验，什么是符号思考，什么是田野调查等等。通过初步阅读，我做出判断，《聪明的阅读者》这本书的作者主要使用了思想实验、田野调查和文采美感这三种认知方式。

为什么会有这样的判断呢？这是我在阅读过程中发现的线索。例如，作者在文章开篇时会设问，引导我们去思考某个问题，这就是思想实验的一种应用。再者，我了解到作者翻阅了人类文明的大部分优秀著作来撰写这本书，这就是田野调查的表现。且在阅读过程中，我发现作者创造了很多新颖的词汇，每篇文章的结尾都有优美的金句，全书的文笔简洁清晰，这又体现了文采美感的认知方式。

对于作者的认知方式做出判断后，我们就可以互动地阅读，比如评价作者的思想实验是否巧妙等。在完成结构阅读之后，我们可以进行抽样阅读，挑选感兴趣的章节阅读，比如我对第五章非常感兴趣。在抽样阅读时，我们带着假设进行，例如，假设作者真实的认知方式是否如我之前所判断：思想实验，田野调查和文采美感。我们可以阅读并验证这个假设。例如，作者在文章开篇时提出了一个问题：我们一生中能读到多少书，这陈述了思想实验的假设。

针对一个问题，他提出了一个见解：在时间有限、专注力有限的条件下，如果想尽可能多地阅读那些代表人类智慧的杰作，创维阅读是一种值得推荐的方法。以此，我们确定了作者确实运用了思想实验的认知方式，并且激发了我对这一章节的阅读兴趣。因此，我也计划对这一章进行仔细阅读。

如果有人希望了解阅读的底层原理，他们可以阅读《聪明的阅读者》的第一篇《何为读》。如果像我这样想要知道更多实用的阅读技巧，我们可以优先阅读第二篇《如何阅读》。而阅读完这本书之后，你可能会感兴趣，其他人是如何阅读的？阅读的原理是怎样的？如何在教育领域应用？你可以围绕阅读主题进行专题阅读。

在阅读过程中，笔头需要经常运动，这就需要了解一些笔记记录技巧，比如我们推荐的卡片法。我将介绍什么是卡片法。卡片法是一种以卡片为基本单位的写作方法，既可以用于阅读，也可以用于写作。在《聪明的阅读者》这本书中，阳志平教授提到，他会在阅读时不断在卡片上记下心得，写作时也会在卡片上写下一些灵感，然后快速检索过往卡片，并整理成文章。从西方的纳博科夫、艾科到中国的鲁迅、钱钟书，他们都是卡片法的实践者。

许多人提倡卡片法的原因是，它可以降低我们的认知负荷并降低写作难度。因此，写卡片时你可以随心所欲，想写什么就写什么。在《聪明的阅读者》中，作者详细介绍了九种卡片的写法，熟悉这些卡片的格式可以进一步降低我们的认知负荷，方便日后查阅。在接下来的第三讲到第七讲的课程中，我们会陆续收到撰写这九种卡片的任务，并在阅读和练习中进一步掌握卡片写作要领。

这九种卡片分别是：基础卡、行动卡、分析卡、人物卡、图示卡、事件卡、新词卡和金句卡。我们首先来看基础卡，其信息结构包括：标题、内容、参考和唯一编码。比如，我撰写的一张基础卡：

标题是「卡片法之撰写基础卡」，内容是：今天阅读《聪明的阅读者》第八章，我了解到撰写基础卡的信息结构是标题加内容加参考加唯一编码，参考则是阳志平的《聪明的阅读者》。唯一编码是一个形如 '2023-0526-00' 的序列。

接下来我要为你演示如何制作一张「行动卡」。行动卡旨在记录你从阅读中获得的行动启示。一张典型的行动卡包括标题、理论、行动、参考文献和唯一编码。

在右侧示例中，我在基础卡片上增加了一个行动提示，然后写下一张行动卡。这一行动提示便是我们的行动，这就是一张标准的行动卡。你可以看到我会用不同的标记符号来创作这样的卡片，比如，标题我用 '＃' 来表示，理论我用「T」表示，行动我会用「A」表示，参考则用「REF」，而唯一编码则用「UUID」来表示，这些都是可以使用的符号。

然后我们看一下另一种卡片，「新知卡」。新知卡是记录我们在阅读中遇到的挑战、扩展认知的卡片，又称为反常识卡。例如，你通过阅读获得了什么新的理论模型、新的推断证据等。典型的新知卡包括标题、已知的知识、新知识、例子、参考和唯一编码。在右侧的新知卡例子中，标题是「卡片法之撰写新知卡」，已知的是「对于阅读需要写卡片来记录，卡片主要由标题、正文、参考、唯一编码组成」。我的新知识是「对于不同的阅读内容，卡片的形式也会不同，应根据这些内容调整卡片的形式，使之更符合内容特点。新知卡主要由标题、已知知识、新知识、例子、参考和唯一编码组成」。例子引用自阳志平的《聪明的阅读者》，唯一编码是 '2023-0525-02'。

接着，我们看「术语卡」。术语卡记录的是阅读过程中出现过的陌生术语或概念。常见的术语卡结构是：标题、定义、解释、例子、参考和唯一编码。例如，我给出的一个案例是关于「唯一编码」。定义是：唯一编码是卡片的唯一标识；解释是：最常用的编码系统是时间或数字加字母，对于初学者，建议使用时间作为编码系统，因为更节省精力。作者建议精确到分钟，使用 12 位的时间戳。例子就是 '2023-0527-1317', 它表示 2023 年 5 月 27 日 13 点 17 分所撰写的卡片。参考文献是梁志平的《聪明的阅读者》，唯一编码为 '2023-0526-03'。

最后看「人物卡」。人物卡旨在记录阅读中遇到的人物。它的结构包括小传、参考和唯一编码。在编写小传时，需要注意记录一些基本的信息。

人物卡的内容包括人物的生卒年份、教育背景、工作经历、主要身份、家庭、社交网络、社会关系等，如果是外国人物，还需包括英文全称。例如，这个人物卡是关于作家纳伯科夫的，他 1899 年出生，1977 年去世，被誉为二十世纪最伟大的作家和「作家中的作家」，著作如《洛丽塔》、《微暗的火》等备受赞誉，他是一位狂热的卡片写作爱好者，同时也是《聪明的阅读者》一书的忠实读者。

图示卡以图画形式来记录阅读时的重要收获，一如俗话，「一图胜千言」。举例来说，标签为「知识创造的三个层次」的图示卡，描述了知识创造的三个层次：卡片层级（创作时间从几分钟到数小时）；文件层级，主要以与他人交谈为主（创作时间从数小时到数天）；以及项目级别，主要以进行社会交易为主，周期从数周到数年。

事件卡常用于记录叙事型文本中的重要事件，通常包含标题、时间、地点、行动者、反应等信息，例如一张描述阳志平教授自我阅读旅程的事件卡：阳老师在 1998 年就读于心理学系时，从大一开始便在图书馆自学并形成自己的阅读方法。

新词卡主要用于积累新词和其用法，可以帮助我们扩大词汇量和提升语感，常见的信息结构为新词加原句加造句加参考加唯一编码。例如，我从苏轼的《超然台记》中收集了「雨雪之争」和「风月之息」两个新词，并用这两个词造了句。

最后是金句子卡，用于记录任何引人入胜的句子。它可以帮助我们提炼和积累好的句子，并在日常写作中进行应用。

以上就是使用大语言模型 GPT 辅助阅读的一些具体做法。

通常，我们可以采用标题、主旨句、评论、仿写、参考、唯一编码的信息结构。一个示范是：标题是「小卡片，大作用」，主旨句来自于《聪明的阅读者》第 196 页的内容「人类用卡片封装的世界，一切都是卡片」。我的评论是：卡片就像积木，承载的可能是一个灵感、一个巧思、一个观点，或者一个信息主块。尽管卡片体积小，但随着卡片的积累，它们可以灵活地拼接成一篇篇文章。你可以参考上述模板写卡片。熟悉后，你可以摒弃模板，根据你的写作习惯发挥。卡片的载体并不限于纸质，也可以在笔记软件中写卡片。

如果你采用电子卡片，你可能需要了解 markdown 语法。markdown 是一种轻量级标记语言，被广泛用于编写带格式的文本，设计目标是易读易写。许多网站和笔记软件已经采纳 markdown 语法。

我们来看一下 markdown 语法的一些基本用法。你只需要几分钟就能学会基础用法，比如标题、文本样式、列表、链接、图片等。在一行的开头，使用 1-6 个井号来创建标题，井号越多，代表的层级越低；使用星号或下划线来标记斜体，两个星号或两条下划线来标记粗体，两条波浪线来标记删除线。在列表中，你可以用星号、加号、减号来创建无序列表，用数字加英文句号来创建有序列表。链接和图片的格式很类似，只是图片的格式多了一个感叹号。最后，我们看一下引用，使用大于号来创建引用。

下面，我们来看一下，对错误的代码应该如何展示。双点号之间显示的是单行代码，而三个点号之间用于嵌入一个代码块。这些符号当中的代码可以以原本的格式呈现给大家。然后，我们再来看一下一些稍微复杂的语法：如何表示表格、横线和复选框？表格相对复杂一些，使用竖线来分割不同的单元格，使用横线来分割表头和其他行。至于表示横线，可以使用三个或更多的横杠、星号或短横线来创建。对于复选框，则可以使用一个中括号表示一个未完成的任务，用中括号加叉号表示已完成的任务。在右图中我给出了一个示例。如果您还没有完全掌握这些 markdown 语法，不需要过于着急。现在我们有了 AI，你只需要向 GPT 提问，「什么是 markdown 语法」，它能出色地提供答案。我在 PPT 的右侧截图了 GPT 以代码框形式直观显示的效果。所以，大家也可以使用 GPT 来复习 markdown 语法。

我们想要清晰探讨到 GPT 对阅读的具体影响，首先需要建立在对 GPT 能力和局限性的理解上。接下来，我们就将从更底层的角度来探索 GPT 的能力与局限。首先，让我们从定义开始了解什么是 GPT。邀请 GPT 自己来做出回答，它的回答是，GPT 是由 OpenAI 开发的自然语言处理的深度学习模型，基于 transformer 架构，被广泛应用于各种 NLP 任务，如翻译、问答、摘要生成等等。我们可以简单地理解，GPT 是一个巨大的神经网络，它从海量数据中学习。GPT 并不查找文本，而是查找某种意义上的匹配内容。

例如，看看这句话：「AI 最好的事情是它的能力能够预测...... 完，下一个单词会是什么呢？」在几十亿文字的训练之后，GPT 的目标实际上是寻找下一个文字出现的概率。假设「学习」有 45% 的概率出现，「预测」有 35% 的概率出现，「做」有 3.2% 的概率，「理解」有 3.1% 的概率，另一个「做」（也是 do 的意思）有 2.9% 的概率出现。那么，你认为 GPT 会选择哪一个单词呢？可能有人会认为，接下来的词肯定是概率最高的，但如果总是选择可能性最高的词，我们得到的文本可能会永远很平淡。

在阅读一些有趣且充满想象力的文章时，我们经常被作者应用的一些少有人用、并非陈词滥调的词语所吸引。同样地，大语言模型 GPT 也能够选择频率并不是很高的文字。它是如何做到的呢？这其实是由「GPT-"temperature"」这个参数实现的。

Temperature 是一个重要的参数用于控制 GPT 模型生成下一个选择的随机文本，也就是用于控制模型输出的多样性。这个参数值的范围通常是在零到一之间。一般来说，"temperature" 越高，模型输出文本的多样性就会越大，模型就更有可能输出不常见的词汇和句子。反之，如果 "temperature" 值越低，则模型的输出更倾向于常见且安全的选项。比如，如果设置 "temperature" 为 0.1，那么模型所生成的文本预测性强且一致性高。而如果 "temperature" 值设为 1，则模型生成的文本将会具有大的随机性和多样性。

举一个实例，如果你正在使用 OpenAI 的 API 来调用模型，你就可以在设置请求中设定 "temperature" 值。下面这个使用 Python 代码的示例便展示了这一点。在示例中，我们给模型提供的一个提示（prm），也就是某个英文文本翻译成法文的请求，然后我们设定了一些其他的参数。比如，最大输出标记数设为 400，"temperature" 设为 0.2，并且频率惩罚和存在惩罚都设为 -0.5。

我们来解释一下其他的参数。首先是 "max_tokens"，它表示单次回复的最大输出标记数，一个标记可以是一个词，一个字或者是一个标点符号。然后是 "frequent_penalty"，表示对训练集中出现频率高的词进行奖励或惩罚，这个参数值的范围通常是在 -0.2 到 2 之间。例如，示例中的 -0.5 表示模型偏向于选择频率高的词。最后是 "presence_penalty"，此参数用于奖励或惩罚在输出中新出现的词，这个参数值的范围也是 -0.2 到 2 之间。例如，示例中设定为 -0.5，表明模型倾向于选择已经在文本中出现频率较高的词。

需要注意的是，这些参数一般在你使用 API 的时候需要手动设置。如果你是使用浏览器来使用 GPT，通常不需要手动设置这些参数。

我曾看到一些精彩的示例，通过指令设定 GPT 的参数。设定不同的参数后，GPT-4 的回答表现出差异。例如，如果我们不设置任何参数，GPT-4 会偏向于以严肃的方式输出答案，它使用的词汇和句子都会更加工整；当我们将温度设置为 0.2，主题的一致性设置为 -0.5 时，它的回答将变得更为轻盈；如果将温度设定为 0.8，主题一致性设置为 -0.5，GPT-4 的用词则会变得更为正式。大家也可以自行在模型中尝试，感受不同参数下的差异。

在 AI 时代，GPT 可能是你首次接触并值得深度关注的模型工具。但如果你自 2023 年 3 月开始关注 AI 发展，可能会被各种术语搞混，例如 GPT-3.5、GPT-4、或 Task-oriented GPT 等。实际上，这些都是 OpenAI 公司的产品。GPT-3.5 是在 2022 年发布的大型语言模型，它的优点是回答速度极快；而 GPT-4 是在 2023 年发布的大型多模态模型，它能接收图像和文本的输入并输出文本，但目前 OpenAI 发布给大部分用户使用的 GPT-4 版本，尚不能接受图像输入。

这个模型展示的能力令人震惊，让我们第一次如此近距离地感受到 AI 的威胁：例如，在许多专业学术的基准测试中，GPT-4 都展示出了人类级别的性能，例如在模拟律师资格考试中，它的得分位于前 10%。

接下来我们继续探索 GPT 的网络浏览功能和插件功能。网络浏览功能是指 GPT 模型能够联网搜索的能力，由于 GPT-3.5 和 GPT-4 的知识库截止到 2021 年的 9 月，已经不能满足我们在 2023 年对知识和信息的需求，所以 OpenAI 开启了 Web GPT 功能，这允许 GPT 浏览网络，以回答最近的主题和事件。插件功能则允许 GPT 使用第三方服务进行计算，以获取最新的消息和信息。

当你使用这个模型时，需要根据需求挑选合适的版本。在 AI 阅读课上，上述的所有模型都会根据具体需求而被使用，此外，专门针对文本阅读的 AI 工具，如 Task-oriented GPT，也会被涉及。以上就是我对 GPT 的简要介绍，感谢大家的聆听。