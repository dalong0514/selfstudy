# 0206. 生命3.0意识 ABC1
> 日课 019丨
万维钢
2017-10-11

前两期日课说的「目的」是个大问题，今天咱们说个更大的问题：意识。这是当今无数聪明人最想搞清楚的问题，也是科学家解决不了、哲学家反复思考、各路牛人一直在吵的问题。

正因为现在还没有特别好的科学理论和科学工具描写意识，有关「意识」的各种讨论的专业性都不怎么强，所谓「前沿」的学说反而都是比较容易理解的。

我想结合迈克斯·泰格马克的《生命3.0》这本书，大概讲讲有关「意识」的最新认识。你看我能不能在两期的时间之内，让你理解现在学术界对「意识」都认识到了什么程度。 

## 1. 细思恐极

有些特别常见、人人都有的东西，只有最聪明的人才能提出问题来。意识人人都有，很少有人质疑，但是如果你仔细想，你会觉得非常不对。AI 给我们思考人类意识提供了一个新角度，用这个更高的视角去看，你甚至会有一种细思恐极的感觉。

你知道你肯定是有意识的。可到底什么是意识呢？

思考，就是意识吗？我们想象一辆自动驾驶的汽车。这辆车随时接收外界的信息，随时处理这些信息，用各种复杂的算法对下一步行动作出自己的决策，它的确会思考。我们承认自动驾驶汽车是有智能的东西，但是它跟你有一个本质区别 —— 我们认为这个区别，就是它没有意识。

你上车了，它对你毫无感觉。把你送到地方、任务完成了，它也不会高兴。在路上遇到红灯停下来了，它也不觉得这是个麻烦。没有油了，他也不觉得饿。遇到危险，它也不害怕。就算撞车了，把自己撞坏了，它也不会觉得疼。它只是找到路线，油不够就去加油，遇到红灯就停，遇到危险就合理避让，它走在路上只是单纯地做着计算，它对走路完全没有任何「感觉」 —— 它没心没肺地把任务完成了。

它只是一台机器 —— 跟玩具汽车没有本质区别，只是多了点智能而已。

那我们跟机器的区别到底在哪呢？显然我们有感情。我们如果需要补充能量了，不但知道去找东西吃，而且会产生「饿」的感情。我们如果遇到危险，不但知道赶紧避让，而且还会产生「害怕」的感情。

从实用的角度，这些感情似乎起到了「思维快捷方式」的作用。之所以我们没吃饭的时候会饿，是因为你饿了，感到难受了，才会赶紧去找吃的。之所以你遇到危险会害怕，是因为你害怕了才能学会避免风险。感情无非也都是算法，是吗？

但是我们讲赫拉利《未来简史》的时候说过的，人也许并不需要感情算法。生物学家对人研究得越深，就越是觉得感情似乎是多余的东西。

人在绝大多数情况下的动作都是本能的反应，并不需要什么感情。比如说你正在路上走，一个足球向你的头部高速飞过来，你本能地就会躲开，根本来不及有什么「感受」，整个动作是无意识的。我们的大脑里已经预先设置好了这种反应程序，我们的这些本能反应跟自动驾驶汽车是一样的。

我们完全也可以像机器人一样生活，饿了就去吃饭，冷了就加件衣服，一切都是本能，不需要附带感情。

那我为什么饿了不但知道要去吃饭，还要感受到痛苦？这个痛苦的感情，到底是个什么东西？

准确地说，我们所有的感情，乃至于不仅仅是「感情」，包括所有的「感觉」，都是对经历的各种事物的，「体验」。更准确地说，是「主观的体验」。

这也是泰格马克在《生命3.0》这本书里选择的意识的定义： 意识，就是主观体验。

客观上，你冷静做好计算，该怎么办怎么办就可以了，可是我们偏偏多了主观体验。 

## 2. 哲学家的洞见

说到这里我们不得不佩服哲学家，哲学家在人类意识这个问题上想得非常深。哲学家的一个洞见是，我们能不能找到一个最基本的东西，来说明意识的存在。

请看下面这张图 ——  

这就是最简单的红色的方块。你看到这个红色，有什么感觉？

也许你联想到喜庆，也许你联想到鲜血，也许你联想到国旗。但是红色有很多种，总有一种红色是你从来都没有见过的，你无法跟任何文化符号联系到一起 —— 但是当你看到这种红色的时候，你还是会有一种感觉。

这种感觉也许是喜欢，也许是不喜欢，也许谈不上喜欢不喜欢，但是你总是对它有一种感觉，要知道有很多感觉根本就不能用语言描述。

如果是一台计算机看这个红色，那无非就是一个光学信号，没有可以多说的，我编码一下就可以了，是什么编码就是什么编码，是什么色号就是什么色号。但是当人看到一个颜色，哪怕是完全陌生的颜色，你还对他产生一种感受，而不是把它当成什么光信号。

1929 年，美国哲学家克拉伦斯·刘易斯（Clarence Irving Lewis）提出一个非常精彩的概念，描写你这个最基本的感受，叫做「感质」，复数形式是 qualia，单数形式是 quale。所谓感质，就是意识的最基本单位。对你来说，红色并不仅仅是一个光信号，它还有感质。你品尝到的每一个味道，听到的每一个声音，都给了你感质。

咱们以前介绍过的哲学家丹尼尔·丹内特，说「感质」有四个特征。

第一，不可言传。 比如说我见到一种你没有见到过的红色，我没有任何办法用语言向你描述看到这种红色是一种什么感觉。我可以给你打比方让你联想，我可以发给你准确的颜色编码让你想象，但是如果你不亲自看一眼，你还是无法准确知道这个红色到底是什么感觉。

我们描写感觉的语言都只是近似的提示而已。

第二，感质是内在的。 因为感质是最基本的意识单元，你总可以把周围环境因素都去掉，最后剩下的红色给你的感觉才是感质。

第三，感质是私人的。 我对红色是什么感觉，你对红色是什么的感觉，咱俩的感觉能不能互相比较一下呢？没法比较，因为不可言传。

第四，可以直接意会。 当你感受到一个感质的时候，你立即就知道你感受到了，不需要再有别的提醒。

丹内特说的这四条可能有点抽象，我举个例子你就明白了。假设现在有个色盲症患者，他从来没见过彩色，他眼中的颜色都是各种各样的灰色。你向他描述了红色的性质，他烂熟于胸，他知道红色代表的各种文化含义，他甚至能从眼中一大堆灰色中准确找到红色，但是他就是不知道红色到底是什么感觉！ 

照片取材于电影 The Giver，一开始的设定是一个完全黑白的世界。

直到有一天，他的色盲症被治好了。他一下子看到了彩色的世界 —— 这时候不用你说任何话，他马上就感受到红色！

这就是意识。如果一个色盲症患者也能生活得很好，我们为什么还要「感受」颜色呢？

## 3. 活人之所以是活人

有些研究计算机的学者觉得意识不重要，但是你仔细想想意识肯定是重要的。意识，是目前为止人和机器的一个本质区别。机器没有主观体验。意识，给了我们「自我」，给了我们「活着」的感觉。

据说现在有的餐馆已经提供机器人端菜服务。如果有一个机器人把菜端给你，你一失手，把很热的菜汤洒到它身上了，你会感到「对不起」它吗？你大概不必有任何愧疚，无非帮它擦干净也就是了。就算你把它损坏了，也只需要给它的主人相应赔偿就可以。对机器人，你不存在什么冒犯不冒犯的问题。

可是如果这个机器人有意识，那就不行了 —— 它可能会感到痛苦。正因为人有意识，有这种主观的体验，才有人权问题，才有道德问题。

如果意识不重要，那么请问短期囚禁虐待一个人，甚至强暴一个女性，又有什么不对的？他们的身体没有受到什么伤害，过段时间就会一切如常。如果一个人就是一堆原子，你做的不过就是临时限制了一下这堆原子的运动，这又有什么不道德呢？

这种行为是犯罪，是因为人不仅仅是一堆原子，是因为人有主观体验 —— 是因为你给她造成了极大的痛苦！

如果将来讨论对待 AI 是否需要道德，大概根本判断标准是这个 AI 有没有意识。有人希望自己死后把全部的思想上传到一个机器人身上，要以机器人的形式继续生存。可是如果机器人的结构不允许意识存在，那它就算获得了你的思想，也只不过是个假装的你而已。 所以 AI 研究的最高级别问题，就是意识。

泰格马克在《生命3.0》这本书里，把现在我们关于意识的问题分为四级。

第一级是「简单」的问题：大脑是怎么处理信息的？大脑的智能到底是怎么工作的？这些问题其实也很难，但毕竟似乎是可以用计算机原理解释的。

第二级是「比较难」的问题：一个有意识的系统和无意识的系统，从物理学来说他们到底有什么区别？

第三级是「更难」的问题：物理性质是怎么决定感质的呢？

第四级是「特别特别难」的问题：为什么宇宙里面居然有意识的存在？

下面这张图是咱们中国的快递包裹分拣机器人。它们忙忙碌碌简简单单，但是非常非常高效。为什么人不是这样的？我们为什么不能该吃吃该喝喝，啥事不往心里搁，为什么要有主观的体验呢？ 

试想在塞外的沙漠里，有一群生物正在默默地工作着。他们的队形整齐，动作有序，以最高的效率获取资源，没有一句废话。

可是就在这时候，其中有一个生物，突然抬起头来，看了看天边的景物，然后居然念了两句诗 —— 

> 大漠孤烟直，长河落日圆。

你不得不承认，因为他这两句诗，整个大漠长河似乎不一样了。可是你不知道为什么要有这两句诗。

不过话说回来，现在科学家虽然说对意识的研究进展很少，但也不是一点进展都没有。明天我们将会介绍一些现代科学对意识的研究，我们已经有一些很有意思的结论，而且最近几年有一个天才人物的确提出一个不一定正确、但绝对高级的关于意识的理论。

咱们明天再说。
 
推荐阅读：

《未来简史》解读2：我有意识，它有吗？
